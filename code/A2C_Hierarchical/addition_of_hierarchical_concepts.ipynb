{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -------------------------------   Imports  -------------------------------  #\n",
    "import gym\n",
    "import minihack\n",
    "from nle import nethack\n",
    "from skimage.io import imshow\n",
    "import numpy as np\n",
    "from CustomRewardManager import RewardManager, InventoryEvent, MessageEvent\n",
    "from actor_critic_v2_hierarchical_options import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------#\n",
    "#                    Custom Sub-Policies - Imported/Defined                      #\n",
    "# -------------------------------------------------------------------------------#\n",
    "class PotionPolicy:\n",
    "    \"\"\"\n",
    "    A Policy loader that reads a stored pytorch file with model and optimizer parameters.\n",
    "\n",
    "    INPUT: The policy should be stored in a file as a dictionary with the format:\n",
    "        {\"model_policy\": policy, \"optimizer\": optimizer}\n",
    "\n",
    "    This policy loader is made specifically for detecting potions in the agent's surrounds.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup for added contextual information\n",
    "    my_dict = {\n",
    "        \"\": 0,\n",
    "        \"floor of a room\": 1,\n",
    "        \"human rogue called Agent\": 1,\n",
    "        \"staircase up\": 3,\n",
    "        \"staircase down\": 4,\n",
    "    }\n",
    "    directions = [\"107\", \"108\", \"106\", \"104\", \"117\", \"110\", \"98\", \"121\", None]\n",
    "    obj_to_find = \"potion\"\n",
    "\n",
    "    def __init__(self, policy_file, actions):\n",
    "        modelA = ActorCritic(h_size=512, a_size=len(actions))\n",
    "        optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.02)\n",
    "\n",
    "        checkpoint = torch.load(policy_file)\n",
    "        modelA.load_state_dict(checkpoint[\"model_policy\"])\n",
    "        optimizerA.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "        modelA.eval()\n",
    "        self.policy = modelA\n",
    "        self.actions = actions\n",
    "\n",
    "    def select_action(self, env, next_state):\n",
    "        # Adding in contextual information\n",
    "        neighbor_descriptions = env.get_neighbor_descriptions()\n",
    "        mapped_descriptions = np.array(\n",
    "            map_descriptions(self.my_dict, neighbor_descriptions)\n",
    "        )\n",
    "        mapped_descriptions = mapped_descriptions.reshape((1, len(mapped_descriptions)))\n",
    "\n",
    "        selected_directions = env.get_object_direction(self.obj_to_find)\n",
    "        selected_directions_encoded = np.zeros(len(self.directions), dtype=int)\n",
    "        index = self.directions.index(\n",
    "            str(selected_directions)\n",
    "            if selected_directions is not None\n",
    "            else selected_directions\n",
    "        )\n",
    "        selected_directions_encoded[index] = 1\n",
    "        selected_directions_encoded = np.array(\n",
    "            selected_directions_encoded.reshape((1, len(selected_directions_encoded)))\n",
    "        )\n",
    "        # Using the stored policy to generate the next set of action probabilities\n",
    "        action_probs, state_value = self.policy.forward(\n",
    "            next_state, mapped_descriptions, selected_directions_encoded\n",
    "        )\n",
    "        distribution = torch.distributions.Categorical(action_probs)\n",
    "        action = distribution.sample()\n",
    "        return action.item()\n",
    "\n",
    "\n",
    "class DrinkPolicy:\n",
    "    \"\"\"Defined policy for confirming an action. Two steps are required to complete this Option.\"\"\"\n",
    "\n",
    "    def __init__(self, consumable):\n",
    "        self.policy_step = 1\n",
    "        self.consumable = consumable\n",
    "\n",
    "    def select_action(self, env, observation=None):\n",
    "        if self.policy_step == 1:\n",
    "            self.policy_step += 1\n",
    "            return nethack.Command.QUAFF\n",
    "        else:\n",
    "            inv_key = env.key_in_inventory(self.consumable)\n",
    "            for action in env.actions:\n",
    "                if ord(inv_key) == action.value:\n",
    "                    return action\n",
    "            print(f\"Confirm action '{inv_key}' not found in those available\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------#\n",
    "#                               Termination Events                               #\n",
    "# -------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "class InventoryTerminationEvent:\n",
    "    \"\"\"An event which checks whether a specified object is in the inventory.\"\"\"\n",
    "\n",
    "    def __init__(self, inv_item: str):\n",
    "        \"\"\"Initialise the Event.\"\"\"\n",
    "        self.inv_item = inv_item\n",
    "\n",
    "    def check_complete(self, env, observation) -> float:\n",
    "        # del previous_observation, action, observation\n",
    "        inventory_items = observation[\"inv_strs\"]\n",
    "        for inv_item in inventory_items:\n",
    "            if self.inv_item in inv_item[\n",
    "                : np.where(inv_item == 0)[0][0]\n",
    "            ].tobytes().decode(\"utf-8\"):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class MessageTerminationEvent:\n",
    "    \"\"\"An event which checks whether a specified message is received.\"\"\"\n",
    "\n",
    "    def __init__(self, messages: str):\n",
    "        \"\"\"Initialise the Event.\"\"\"\n",
    "        self.messages = messages\n",
    "\n",
    "    def check_complete(self, env, observation) -> float:\n",
    "        try:\n",
    "            msg = observation[\"message\"]\n",
    "            curr_msg = msg[: np.where(msg == 0)[0][0]].tobytes().decode(\"utf-8\")\n",
    "            for msg in self.messages:\n",
    "                if msg in curr_msg:\n",
    "                    return True\n",
    "        except:\n",
    "            print(\"Failed to decode message:\")\n",
    "            print(observation[env._original_observation_keys.index(\"message\")])\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------#\n",
    "#                               Sample Options Setup                             #\n",
    "# -------------------------------------------------------------------------------#\n",
    "\n",
    "MOVE_ACTIONS = tuple(nethack.CompassDirection)\n",
    "NAVIGATE_ACTIONS = MOVE_ACTIONS + (\n",
    "    nethack.Command.OPEN,\n",
    "    nethack.Command.KICK,\n",
    "    nethack.Command.SEARCH,\n",
    "    nethack.Command.FIGHT,\n",
    ")\n",
    "\n",
    "# Lava ENV -- extra actions needed for confirming action\n",
    "LAVA_ACTIONS = NAVIGATE_ACTIONS + (\n",
    "    nethack.Command.PICKUP,\n",
    "    nethack.Command.APPLY,\n",
    "    nethack.Command.PUTON,\n",
    "    nethack.Command.WEAR,\n",
    "    nethack.Command.QUAFF,\n",
    "    nethack.Command.INVOKE,\n",
    "    nethack.Command.CAST,\n",
    "    nethack.Command.INVENTORY,\n",
    "    nethack.MiscAction.MORE,\n",
    "    nethack.Command.ESC,\n",
    "    nethack.Command.FIRE,  # most commonly needed confirmation action\n",
    "    nethack.Command.DROP,\n",
    "    nethack.Command.RUSH,\n",
    ")\n",
    "\n",
    "des_file = \"\"\"\n",
    "MAZE: \"mylevel\", ' '\n",
    "FLAGS:hardfloor\n",
    "INIT_MAP: solidfill,' '\n",
    "GEOMETRY:center,center\n",
    "MAP\n",
    "--------\n",
    "|...L..|\n",
    "|...L..|\n",
    "|...L..|\n",
    "--------\n",
    "ENDMAP\n",
    "REGION:(0,0,6,3),lit,\"ordinary\"\n",
    "$left_bank = selection:fillrect (1,1,3,3)\n",
    "$right_bank = selection:fillrect (5,1,6,3)\n",
    "OBJECT:('!',\"levitation\"),rndcoord($left_bank),blessed\n",
    "BRANCH:(1,1,3,3),(0,0,0,0)\n",
    "STAIR:rndcoord($right_bank),down\n",
    "\"\"\"\n",
    "\n",
    "# Specify RewardManager for reward shaping\n",
    "reward_manager = RewardManager()\n",
    "# Reward for adding a potion to the inventory\n",
    "reward_manager.add_event(InventoryEvent(0.5, False, True, False, inv_item=\"potion\"))\n",
    "# Message based reward after drinking a levitation potion\n",
    "reward_manager.add_event(\n",
    "    MessageEvent(0.5, False, True, False, messages=[\"You start to float in the air!\"])\n",
    ")\n",
    "# Add a penalty reward for entering the lava\n",
    "reward_manager.add_location_event(\"molten lava\", reward=-1, terminal_required=False)\n",
    "# Add reward for reaching the final destination and set it to terminal\n",
    "reward_manager.add_location_event(\n",
    "    \"staircase down\",\n",
    "    reward=1,\n",
    "    repeatable=False,\n",
    "    terminal_required=True,\n",
    "    terminal_sufficient=True,\n",
    ")\n",
    "\n",
    "env = gym.make(\n",
    "    \"MiniHack-Skill-Custom-v0\",\n",
    "    des_file=des_file,\n",
    "    observation_keys=[\n",
    "        \"glyphs\",\n",
    "        \"pixel\",\n",
    "        \"message\",\n",
    "        \"pixel_crop\",\n",
    "        \"glyphs_crop\",\n",
    "        \"blstats\",\n",
    "        \"inv_strs\",\n",
    "    ],\n",
    "    reward_manager=reward_manager,\n",
    "    # reward_lose=-1, # Does not work when reward manager is used\n",
    "    actions=LAVA_ACTIONS,\n",
    "    autopickup=True,\n",
    "    allow_all_modes=True,  # Enables confirmation message for consuming potion\n",
    "    max_episode_steps=500,\n",
    ")\n",
    "\n",
    "# Option 1: Loaded policy that's trained to find and pickup a potion\n",
    "termination_clause = InventoryTerminationEvent(\"potion\")\n",
    "potion_policy = PotionPolicy(\n",
    "    \"./policy_potion_pickup_with_neighbours_2000.pt\", MOVE_ACTIONS\n",
    ")\n",
    "# Option 2: Defined policy for consuming a potion in the agent's inventory\n",
    "drink_policy = DrinkPolicy(\"potion\")\n",
    "levitation_message = MessageTerminationEvent([\"You start to float in the air!\"])\n",
    "\n",
    "# Specify the set of Options, including the primitive actions\n",
    "ENV_OPTIONS = [(action, None, 1) for action in env.actions] + [\n",
    "    (potion_policy, termination_clause, 20),\n",
    "    (drink_policy, levitation_message, 2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with options instead of actions\n",
    "policy, results, optimizer = run_actor_critic(\n",
    "    env,\n",
    "    number_episodes=5000,\n",
    "    max_episode_length=1000,\n",
    "    iterations=3,\n",
    "    env_options=ENV_OPTIONS,\n",
    ")\n",
    "\n",
    "# Save and process results\n",
    "torch.save(\n",
    "    {\"model_policy\": policy.state_dict(), \"optimizer\": optimizer.state_dict()},\n",
    "    \"./policy_potion_pickup_with_options.pt\",\n",
    ")\n",
    "plot_results(\n",
    "    env_name=\"Lava Cross with Potion Pickup Option\",\n",
    "    scores=results,\n",
    "    ylim=(-1.5, 2),\n",
    "    color=\"teal\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
